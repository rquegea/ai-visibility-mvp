# src/engines/openai.py
"""
Wrapper de utilidades para la **OpenAI Python >= 1.0**.
Expone tres funciones:

    â€¢ fetch_response()    â†’ texto â€œcrudoâ€ del modelo
    â€¢ analyze_sentiment() â†’ (sentiment, emotion, confidence)
    â€¢ extract_insights()  â†’ JSON rico para dashboards

Todas las llamadas usan la nueva sintaxis v1 (`client.chat.completions.create`).
"""

from __future__ import annotations

import json
import logging
import os
from typing import Any, Dict, List, Tuple

from dotenv import load_dotenv
from openai import OpenAI, OpenAIError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()  # lee .env local o variables de VPS
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Funciones auxiliares â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_response(
    prompt: str,
    *,
    model: str = "gpt-4o-mini",
    temperature: float = 0.3,
    max_tokens: int = 1_024,
) -> str:
    """
    EnvÃ­a un prompt y devuelve la **respuesta textual** del modelo.
    Deja trazas en el log para debugging.
    """
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Eres un asistente Ãºtil. "
                        "Sigue exactamente las instrucciones del usuario."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        answer: str = res.choices[0].message.content.strip()
        return answer
    except OpenAIError as exc:  # errores propios del SDK
        logger.exception("âŒ OpenAI API error: %s", exc)
        raise


def analyze_sentiment(text: str) -> Tuple[float, str, float]:
    """
    Devuelve (sentiment, emotion, confidence) a partir de un bloque de texto.
      â€¢ sentiment  âˆˆ [-1, 1]   (<0 negativo, >0 positivo)
      â€¢ emotion    âˆˆ {alegrÃ­a, tristeza, â€¦}
      â€¢ confidence âˆˆ [0, 1]
    """
    meta_prompt = (
        'Responde SOLO con JSON con tres campos: '
        '{"sentiment": -0.25, "emotion": "alegrÃ­a", "confidence": 0.87}.\n\n'
        "Texto a analizar:\n"
    )
    raw = fetch_response(meta_prompt + text, temperature=0)
    try:
        obj = json.loads(raw)
        return (
            float(obj.get("sentiment", 0)),
            str(obj.get("emotion", "neutral")),
            float(obj.get("confidence", 0.5)),
        )
    except Exception as exc:
        logger.error("âŒ Error parsing sentiment JSON: %s -- raw: %s", exc, raw)
        return 0.0, "neutral", 0.5


def extract_insights(text: str) -> Dict[str, Any]:
    """
    Analiza el CONTENIDO (p.ej. respuesta larga de GPT-4 / Perplexity / SERP)
    y devuelve un JSON listo para guardarse en la tabla **insights**.

    El prompt genera:
      â€¢ brands (nombre, nÂº menciones, sentimiento medio)
      â€¢ competitors
      â€¢ opportunities / risks / pain_points / trends
      â€¢ quotes
      â€¢ top_themes / topic_frequency / source_mentions / calls_to_action
      â€¢ audience_targeting / products_or_features
    """
    prompt = f"""
Eres un **analista senior de inteligencia de mercado**.

1ï¸âƒ£ Lee atentamente el CONTENIDO.  
2ï¸âƒ£ Identifica **todas las MARCAS o productos** citados.  
3ï¸âƒ£ Cuenta cuÃ¡ntas veces aparece cada marca.  
4ï¸âƒ£ EvalÃºa el **sentimiento promedio** hacia cada marca (âˆ’1 â€¦ 1).  
5ï¸âƒ£ Detecta **competidores** relevantes.  
6ï¸âƒ£ Extrae **insights accionables** agrupados en:
   â€¢ opportunities â€“ crecimientos, tendencias favorables  
   â€¢ risks         â€“ amenazas, crÃ­ticas, quejas recurrentes  
   â€¢ pain_points   â€“ fricciones (logÃ­stica, precio, saborâ€¦)  
   â€¢ trends        â€“ comportamientos emergentes (healthy, vegan, premiumâ€¦)  
7ï¸âƒ£ AÃ±ade **hasta 3 QUOTES** literales (â‰¤ 200 caracteres) que representen el tono.  
8ï¸âƒ£ Identifica los temas mÃ¡s importantes tratados (top themes).  
9ï¸âƒ£ Cuenta las **palabras clave frecuentes** (â‰¥ 2 repeticiones).  
ğŸ”Ÿ Si se citan dominios (ej. forbes.com, builtin.com), indica cuÃ¡ntas veces.  
1ï¸âƒ£1ï¸âƒ£ Si hay frases tipo *â€œlas empresas deberÃ­anâ€¦â€*, guÃ¡rdalas como calls_to_action.  
1ï¸âƒ£2ï¸âƒ£ Si se infiere un pÃºblico objetivo claro (ej. CFOs, startups), indÃ­calo.  
1ï¸âƒ£3ï¸âƒ£ Lista funcionalidades o productos destacados (ej. Corporate Cards, AP Automation).

Devuelve SOLO un objeto **JSON** con este formato EXACTO:

{{
  "brands": [{{"name": "...", "mentions": <int>, "sentiment_avg": <float>}}, â€¦],
  "competitors": ["...", "..."],
  "opportunities": ["...", "..."],
  "risks": ["...", "..."],
  "pain_points": ["...", "..."],
  "trends": ["...", "..."],
  "quotes": ["...", "..."],
  "top_themes": ["...", "..."],
  "topic_frequency": {{"keyword": <int>, ...}},
  "source_mentions": {{"domain": <int>, ...}},
  "calls_to_action": ["...", "..."],
  "audience_targeting": ["...", "..."],
  "products_or_features": ["...", "..."]
}}

No aÃ±adas texto fuera del JSON.
----------
CONTENIDO:
{text}
----------
"""
    raw = fetch_response(prompt, temperature=0.2, max_tokens=1800)
    try:
        data: Dict[str, Any] = json.loads(raw)
        return data
    except Exception as exc:
        logger.error("âŒ Error extracting insights: %s\nRespuesta del modelo: %s", exc, raw)
        return {}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ejemplo CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    SAMPLE = (
        "Rho ha aumentado su presencia en medios como Forbes y BuiltIn. "
        "Los CFOs destacan sus herramientas de automatizaciÃ³n de pagos y tarjetas corporativas. "
        "Algunos piden mejoras en integraciones con ERPs. Las empresas deberÃ­an adoptar mÃ¡s soluciones integradas."
    )
    print(json.dumps(extract_insights(SAMPLE), indent=2, ensure_ascii=False))
